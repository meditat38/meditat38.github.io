<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Moritz Gnann</title>
        <link rel="stylesheet" href="style.css">
        <script defer src="app.js"></script>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Anonymous+Pro:wght@400;700&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Baloo+2:wght@500;800&family=Ubuntu:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
    </head>
    <body>
        <div class="wrapper">
            <section class="header hidden2" id="header">
                <div class="headerBG"></div>
                <nav>
                    <div class="logo">
                        <ul>
                            <li><a class="logo" href="index.html"><b>Moritz Gnann</b></a></li>
                        </ul>
                    </div>
                    <div class="nav-links">
                        <ul>
                            <li><a href="index.html#headlineProjects"><b>projects</b></a></li>
                            <li><a href="index.html#aboutHeadline"><b>about</b></a></li>
                            <li><a href="index.html#form"><b>contact</b></a></li>
                        </ul>
                    </div>
                </nav>        
            </section>
    
            <div class="Background">
                <img class="bg2" src="images/noise2.png">
          </div>
    
            <section class="everypaintHeadline">
                <h2><b>AUTO-NOM</b></h2>
                <h4>I see something you don't see</h4>
            </section>
            <section class="text">
                <h4>Automobiles already collect and process a wide range of sensor data: Ultrasound monitors the close-range area when parking, for example, while radar systems maintain the distance or perform emergency braking. In autonomously driving cars, lidar laser scanning generates three-dimensional images of the physical surroundings, and camera images allow objects in the environment to be classified using image processing. This diverse information about the driving car's environment is processed in real time and supplemented by other sensor data, such as acceleration values and GPS coordinates, so that a car can move as safely and accident-free as possible in complex road traffic without the assistance and supportive intervention of a human.</h4>
            </section>
            <section class="hopohopoTrailer">
                <video class= "video" poster="images/autonom.png" muted autoplay loop controls>
                    <source src="videos/DSCF4766.mp4" type="video/mp4">
                    Your browser does not support mp4 videos!               
                  </video>
            </section>
            <section class="text">
                <h4>In the VR-Experience "AUTO-NOM - I see something you don't see" by Leon Döring and Moritz Gnann, the seemingly infinitely large amounts of data that a self-driving car automatically collects in a very short time and processes in real time are examined. Using a 2.3 terabyte dataset of sensor information from an Audi test vehicle (Audi Autonomous Driving Dataset A2D2, 2020) that is freely available via the Internet, this application uses VR technology to make this simultaneously highly precise and yet surprisingly speculative view of the city visible to the human eye. Based on an approximately 15-minute test drive through downtown Munich, data from different sensor systems is visually processed. Sitting on a car seat, the dynamic 3D data can be viewed either freely via VR glasses or via a triple video projection in the gallery space. The recognition of surrounding objects (pedestrians, trucks, bicycles, traffic lights, etc.), which is central to the car's decision-making process and is expressed as percentage probabilities, is also superimposed on the viewing space. Furthermore, non-visual information such as acceleration values or steering angles are converted into sound patterns that support the virtual movement of the car through Munich in a space-filling manner.</h4>
            </section>

            <section class="gridContainer3">
                <div class="image-grid3">
                    <img src="images/DSCF1300.jpeg" alt="autonomScreenshot">
                    <img src="images/Screenshot 2022-08-01 000804.jpeg" alt="autonomScreenshot">
                    <img class="image-grid-col-2 image-grid-row-2" src="images/DSCF1473.jpeg" alt="autonomScreenshot">
                    <img src="images/Screenshot 2022-08-01 002729.jpeg" alt="autonomScreenshot">
                    <img src="images/Screenshot 2022-08-01 002735.jpeg" alt="autonomScreenshot">
                    <img class="image-grid-col-2 image-grid-row-3" src="images/Isometrie.jpeg" alt="autonomScreenshot">                   
                </div>        
            </section>

            <section class="text">
                <h4>My task in this work was to visually represent the sensor data processed for me by Leon Döring in VR. The main task was to display the point clouds, which are generated by the lidar laser scanners, in real-time in VR. Each point cloud consists of about 200,000 points and changes 30 times a second, which means about 27,000 point clouds during a 15-minute test drive.
                    <p><br>To do this, I converted the position coordinates and brightness values of the individual points into HDR color information and exported them as individual pixels in an .exr image file (see image below). This color information can then be read into Unity's Vfx graph and converted back to position data, which can then be used to place the individual points through the Vfx graph. With an animation of these .exr image files, the point clouds can be displayed in VR in realtime without much computing power.</p></h4>
            </section>

            <section class="gridContainer3">
                <div class="image-grid3">
                    <img class="image-grid-col-2 image-grid-row-2" src="images/textures2_1 (0-00-00-00).jpg" alt="positionTexture">                  
                </div>        
            </section>

            <section class="text">
                <h4>The work was shown from June 18 to 26, 2022 as part of the Virtual Summer School GREY BOX TESTING* exhibition at the Architekturgalerie München (<a href="https://www.architekturgalerie-muenchen.de/programm/detail/news/detail/News/grey-box-testing.html" target="_blank">https://www.architekturgalerie-muenchen.de</a>) and was nominated for the cityvis competition 2022 (<a href="https://www.cityvis.io/competitions/2022/" target="_blank">https://www.cityvis.io/competitions/2022/</a>).</p></h4>
            </section>

            <section class="gridContainer3">
                <section class="headlineRecommendations">
                    <b>Check out my other projects!</b>
                </section>
                <section class="recommendations">
                    <nav>
                        <figure>
                            <ul>
                                <li><a href="hopohopo.html"><img src="images/hopohopo.png"><figcaption><h1><b>hopohopo</b><br></h1></figcaption></a></li>                        
                            </ul>                   
                        </figure>
                        <figure>
                            <ul>
                                <li><a href="everypaint.html"><img src="images/everypaint.jpg">
                                <figcaption><h1><b>everypaint</b><br></h1></figcaption>    
                                </a></li>                                               
                            </ul>                    
                        </figure>
                        <figure>
                            <ul>
                                <li><a href="kingspray.html"><img src="images/kingspray.PNG"><figcaption><h1><b>Worldbuilding</b><br></h1></figcaption></a></li>                        
                            </ul>                   
                        </figure>
                    </nav>
                </section>
            </section>
                        
            <footer>Moritz Gnann // moritzgnann@gmx.de // Berlin</footer>
        </div>
        <a href="#header">
            <section class="upButton">
            <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-up-circle-fill" viewBox="0 0 16 16">
                <path d="M16 8A8 8 0 1 0 0 8a8 8 0 0 0 16 0zm-7.5 3.5a.5.5 0 0 1-1 0V5.707L5.354 7.854a.5.5 0 1 1-.708-.708l3-3a.5.5 0 0 1 .708 0l3 3a.5.5 0 0 1-.708.708L8.5 5.707V11.5z"/>
              </svg>                
        </section>
        </a>
        <div class="languageSelector">
            <ul>
                <li><a href="auto-nom.html"><b>EN</b></a></li><li><a href="auto-nomDE.html"><b>DE</b></a></li>
            </ul>
        </div>
    </body>
</html>